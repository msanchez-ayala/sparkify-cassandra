{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I. ETL Pipeline for Pre-Processing the Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLEASE RUN THE FOLLOWING CODE FOR PRE-PROCESSING THE FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cassandra\n",
    "from cassandra.cluster import Cluster\n",
    "import os\n",
    "import glob\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get absolute filepath of event_data directory\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "# join the file path and roots with the subdirectories using glob\n",
    "file_path_list = glob.glob(os.path.join(filepath,'*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing the files to create the data file csv that will be used for Apache Casssandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full combined CSV data contains 8056 rows.\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list of rows that will be generated from each file\n",
    "full_data_rows_list = [] \n",
    "    \n",
    "# For every filepath in the file path list \n",
    "for f in file_path_list:\n",
    "\n",
    "    # Read csv file \n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        \n",
    "        # Create a csv reader object \n",
    "        csvreader = csv.reader(csvfile) \n",
    "        \n",
    "        # Skip header row (column names)\n",
    "        next(csvreader)\n",
    "        \n",
    "        # Extract each row of data and append        \n",
    "        for line in csvreader:\n",
    "            full_data_rows_list.append(line) \n",
    "            \n",
    "print('Full combined CSV data contains', len(full_data_rows_list), 'rows.')           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered CSV File contains 6821 rows.\n"
     ]
    }
   ],
   "source": [
    "# Create a smaller event data csv file called event_datafile_full.csv that will be inserted \n",
    "# into the Apache Cassandra tables\n",
    "\n",
    "# Create custom dialect to parse CSV\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "# Create new csv to store data and instantiate a writer object\n",
    "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    \n",
    "    # Name columns\n",
    "    writer.writerow([\n",
    "        'artist',\n",
    "        'first_name',\n",
    "        'gender',\n",
    "        'item_in_session',\n",
    "        'last_name',\n",
    "        'length',    \n",
    "        'level',\n",
    "        'location',\n",
    "        'session_id',\n",
    "        'song',\n",
    "        'user_id'\n",
    "    ])\n",
    "    \n",
    "    # Iterate through each row in the data list\n",
    "    for row in full_data_rows_list:\n",
    "        \n",
    "        # Filter out rows from CSVs that don't deal with song plays\n",
    "        if row[0] != '':\n",
    "            \n",
    "            # Store only relevant features\n",
    "            writer.writerow((\n",
    "                row[0], \n",
    "                row[2], \n",
    "                row[3], \n",
    "                row[4], \n",
    "                row[5], \n",
    "                row[6], \n",
    "                row[7], \n",
    "                row[8], \n",
    "                row[12], \n",
    "                row[13], \n",
    "                row[16]\n",
    "            ))\n",
    "\n",
    "# check the number of rows in your csv file\n",
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print('Filtered CSV File contains', sum(1 for line in f), 'rows.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II. Complete the Apache Cassandra coding portion of your project. \n",
    "\n",
    "Now you are ready to work with the CSV file titled <font color=red>event_datafile_new.csv</font>, located within the Workspace directory.  The event_datafile_new.csv contains the following columns: \n",
    "- artist \n",
    "- firstName of user\n",
    "- gender of user\n",
    "- item number in session\n",
    "- last name of user\n",
    "- length of the song\n",
    "- level (paid or free song)\n",
    "- location of the user\n",
    "- sessionId\n",
    "- song title\n",
    "- userId\n",
    "\n",
    "The image below is a screenshot of what the denormalized data should appear like in the <font color=red>**event_datafile_new.csv**</font> after the code above is run:<br>\n",
    "\n",
    "<img src=\"images/image_event_datafile_new.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin writing your Apache Cassandra code in the cells below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should make a connection to a Cassandra instance your local machine \n",
    "# (127.0.0.1)\n",
    "try:\n",
    "    # Create a connection to the docker image\n",
    "    cluster = Cluster(['127.0.0.1'], port=9042)\n",
    "    session = cluster.connect()\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    session.execute(\"\"\"\n",
    "        CREATE KEYSPACE IF NOT EXISTS \n",
    "          sparkify \n",
    "        WITH REPLICATION = {\n",
    "            'class': 'SimpleStrategy', \n",
    "            'replication_factor': 1\n",
    "        }\n",
    "    \"\"\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    session.set_keyspace('sparkify')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create queries to ask the following three questions of the data\n",
    "\n",
    "1. Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4\n",
    "\n",
    "\n",
    "2. Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "    \n",
    "\n",
    "3. Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 1\n",
    "### CQL Queries and Table Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CQL Queries\n",
    "select_query_1 = \"\"\"\n",
    "    SELECT \n",
    "      artist, \n",
    "      song, \n",
    "      length \n",
    "    FROM \n",
    "      song_info \n",
    "    WHERE \n",
    "      session_id = 338 AND \n",
    "      item_in_session = 4\n",
    "\"\"\"\n",
    "\n",
    "create_query_1 = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS\n",
    "      song_info (\n",
    "        artist text,\n",
    "        item_in_session int,\n",
    "        length float,\n",
    "        session_id int,\n",
    "        song text,\n",
    "        PRIMARY KEY (session_id, item_in_session)\n",
    "      )\n",
    "\"\"\"\n",
    "\n",
    "insert_query_1 = \"\"\"\n",
    "    INSERT INTO \n",
    "      song_info (\n",
    "        artist,\n",
    "        item_in_session,\n",
    "        length,\n",
    "        session_id,\n",
    "        song\n",
    "      )\n",
    "    VALUES\n",
    "      (%s, %s, %s, %s, %s)\n",
    "\"\"\"\n",
    "\n",
    "insert_query_1s = \"\"\"\n",
    "    INSERT INTO \n",
    "      song_info (\n",
    "        artist,\n",
    "        item_in_session,\n",
    "        length,\n",
    "        session_id,\n",
    "        song\n",
    "      )\n",
    "    VALUES\n",
    "      (?, ?, ?, ?, ?)\n",
    "\"\"\"\n",
    "        \n",
    "try:\n",
    "    session.execute(create_query_1)\n",
    "except Exception as e:\n",
    "    print(e)                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Read filtered CSV\n",
    "with open('event_datafile_new.csv', encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    \n",
    "    # Skip header row (column names)\n",
    "    next(csvreader)\n",
    "    \n",
    "    for line in csvreader:\n",
    "        \n",
    "        # Insert each row into table\n",
    "        session.execute(\n",
    "            insert_query_1, \n",
    "            (line[0], int(line[3]), float(line[5]), int(line[8]), line[9])\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify Data Insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faithless Music Matters (Mark Knight Dub) 495.30731201171875\n"
     ]
    }
   ],
   "source": [
    "# Confirm data was inserted\n",
    "rows = session.execute(select_query_1)\n",
    "for (artist, song, length) in rows:\n",
    "    print(artist, song, length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 2\n",
    "### CQL Queries and Table Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO-DO: Query 2: Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name)\\\n",
    "## for userid = 10, sessionid = 182\n",
    "\n",
    "# PRIMARY KEY (user_id, session_id, item_in_session)\n",
    "select_query_2 = \"\"\"\n",
    "    SELECT \n",
    "      artist, \n",
    "      song, \n",
    "      first_name, \n",
    "      last_name \n",
    "    FROM \n",
    "      users_songs \n",
    "    WHERE \n",
    "      user_id = 10 AND \n",
    "      session_id = 182\n",
    "\"\"\"\n",
    "\n",
    "create_query_2 = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS\n",
    "      users_songs (\n",
    "        artist text,\n",
    "        first_name text,\n",
    "        item_in_session int,\n",
    "        last_name text,\n",
    "        session_id int,\n",
    "        song text,\n",
    "        user_id int,\n",
    "        PRIMARY KEY (user_id, session_id, item_in_session)\n",
    "      )\n",
    "\"\"\"\n",
    "\n",
    "insert_query_2 = \"\"\"\n",
    "    INSERT INTO \n",
    "      users_songs (\n",
    "        artist,\n",
    "        first_name,\n",
    "        item_in_session,\n",
    "        last_name,\n",
    "        session_id,\n",
    "        song,\n",
    "        user_id\n",
    "      )\n",
    "    VALUES\n",
    "      (%s, %s, %s, %s, %s, %s, %s)\n",
    "\"\"\"\n",
    "        \n",
    "try:\n",
    "    session.execute(create_query_2)\n",
    "except Exception as e:\n",
    "    print(e)                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Read filtered CSV\n",
    "with open('event_datafile_new.csv', encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    \n",
    "    # Skip header row (column names)\n",
    "    next(csvreader)\n",
    "    \n",
    "    for line in csvreader:\n",
    "        \n",
    "        # Insert each row into table\n",
    "        session.execute(\n",
    "            insert_query_2, \n",
    "            (\n",
    "                line[0], \n",
    "                line[1], \n",
    "                int(line[3]), \n",
    "                line[4], \n",
    "                int(line[8]), \n",
    "                line[9],\n",
    "                int(line[10])\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify Data Insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Down To The Bone Keep On Keepin' On Sylvie Cruz\n",
      "Three Drives Greece 2000 Sylvie Cruz\n",
      "Sebastien Tellier Kilometer Sylvie Cruz\n",
      "Lonnie Gordon Catch You Baby (Steve Pitron & Max Sanna Radio Edit) Sylvie Cruz\n"
     ]
    }
   ],
   "source": [
    "# Confirm data was inserted\n",
    "rows = session.execute(select_query_2)\n",
    "for (artist, song, first_name, last_name) in rows:\n",
    "    print(artist, song, first_name, last_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 3\n",
    "### CQL Queries and Table Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO-DO: Query 3: Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "# PRIMARY KEY (song, user_id)\n",
    "select_query_3 = \"\"\"\n",
    "    SELECT \n",
    "      first_name, \n",
    "      last_name \n",
    "    FROM \n",
    "      user_name \n",
    "    WHERE \n",
    "      song = 'All Hands Against His Own'\n",
    "\"\"\"\n",
    "\n",
    "create_query_3 = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS\n",
    "      user_name (\n",
    "        last_name text,\n",
    "        first_name text,\n",
    "        song text,\n",
    "        user_id int,\n",
    "        PRIMARY KEY (song, user_id)\n",
    "      )\n",
    "\"\"\"\n",
    "\n",
    "insert_query_3 = \"\"\"\n",
    "    INSERT INTO \n",
    "      user_name (\n",
    "        first_name,\n",
    "        last_name,\n",
    "        song,\n",
    "        user_id\n",
    "      )\n",
    "    VALUES\n",
    "      (%s, %s, %s, %s)\n",
    "\"\"\"\n",
    "        \n",
    "try:\n",
    "    session.execute(create_query_3)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read filtered CSV\n",
    "with open('event_datafile_new.csv', encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    \n",
    "    # Skip header row (column names)\n",
    "    next(csvreader)\n",
    "    \n",
    "    for line in csvreader:\n",
    "        \n",
    "        # Insert each row into table\n",
    "        session.execute(\n",
    "            insert_query_3, (line[1], line[4], line[9], int(line[10])            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify Data Insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jacqueline Lynch\n",
      "Tegan Levine\n",
      "Sara Johnson\n"
     ]
    }
   ],
   "source": [
    "# Confirm data was inserted\n",
    "rows = session.execute(select_query_3)\n",
    "for (first_name, last_name) in rows:\n",
    "    print(first_name, last_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the tables before closing out the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_query_1 = \"DROP TABLE song_info\"\n",
    "drop_query_2 = \"DROP TABLE users_songs\"\n",
    "drop_query_3 = \"DROP TABLE user_name\"\n",
    "\n",
    "drop_queries = [drop_query_1, drop_query_2, drop_query_3]\n",
    "\n",
    "for query in drop_queries:\n",
    "    session.execute(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close the session and cluster connection¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
