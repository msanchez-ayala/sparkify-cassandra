{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I. ETL Pipeline for Pre-Processing the Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLEASE RUN THE FOLLOWING CODE FOR PRE-PROCESSING THE FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cassandra\n",
    "from cassandra.cluster import Cluster\n",
    "import os\n",
    "import glob\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get absolute filepath of event_data directory\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "# join the file path and roots with the subdirectories using glob\n",
    "file_path_list = glob.glob(os.path.join(filepath,'*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing the files to create the data file csv that will be used for Apache Casssandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full combined CSV data contains 8056 rows.\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list of rows that will be generated from each file\n",
    "full_data_rows_list = [] \n",
    "    \n",
    "# For every filepath in the file path list \n",
    "for f in file_path_list:\n",
    "\n",
    "    # Read csv file \n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        \n",
    "        # Create a csv reader object \n",
    "        csvreader = csv.reader(csvfile) \n",
    "        \n",
    "        # Skip header row (column names)\n",
    "        next(csvreader)\n",
    "        \n",
    "        # Extract each row of data and append        \n",
    "        for line in csvreader:\n",
    "            full_data_rows_list.append(line) \n",
    "            \n",
    "print('Full combined CSV data contains', len(full_data_rows_list), 'rows.')           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered CSV File contains 6821 rows.\n"
     ]
    }
   ],
   "source": [
    "# Create a smaller event data csv file called event_datafile_full.csv that will be inserted \n",
    "# into the Apache Cassandra tables\n",
    "\n",
    "# Create custom dialect to parse CSV\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "# Create new csv to store data and instantiate a writer object\n",
    "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    \n",
    "    # Name columns\n",
    "    writer.writerow([\n",
    "        'artist',\n",
    "        'first_name',\n",
    "        'gender',\n",
    "        'item_in_session',\n",
    "        'last_name',\n",
    "        'length',    \n",
    "        'level',\n",
    "        'location',\n",
    "        'session_id',\n",
    "        'song',\n",
    "        'user_id'\n",
    "    ])\n",
    "    \n",
    "    # Iterate through each row in the data list\n",
    "    for row in full_data_rows_list:\n",
    "        \n",
    "        # Filter out rows from CSVs that don't deal with song plays\n",
    "        if row[0] != '':\n",
    "            \n",
    "            # Store only relevant features\n",
    "            writer.writerow((\n",
    "                row[0], \n",
    "                row[2], \n",
    "                row[3], \n",
    "                row[4], \n",
    "                row[5], \n",
    "                row[6], \n",
    "                row[7], \n",
    "                row[8], \n",
    "                row[12], \n",
    "                row[13], \n",
    "                row[16]\n",
    "            ))\n",
    "\n",
    "# check the number of rows in your csv file\n",
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print('Filtered CSV File contains', sum(1 for line in f), 'rows.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II. Complete the Apache Cassandra coding portion of your project. \n",
    "\n",
    "Now you are ready to work with the CSV file titled <font color=red>event_datafile_new.csv</font>, located within the Workspace directory.  The event_datafile_new.csv contains the following columns: \n",
    "- artist \n",
    "- firstName of user\n",
    "- gender of user\n",
    "- item number in session\n",
    "- last name of user\n",
    "- length of the song\n",
    "- level (paid or free song)\n",
    "- location of the user\n",
    "- sessionId\n",
    "- song title\n",
    "- userId\n",
    "\n",
    "The image below is a screenshot of what the denormalized data should appear like in the <font color=red>**event_datafile_new.csv**</font> after the code above is run:<br>\n",
    "\n",
    "<img src=\"images/image_event_datafile_new.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin writing your Apache Cassandra code in the cells below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should make a connection to a Cassandra instance in the Cassandra container \n",
    "try:\n",
    "    # Create a connection to the docker image\n",
    "    cluster = Cluster(['127.0.0.1'], port=9042)\n",
    "    session = cluster.connect()\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    session.execute(\"\"\"\n",
    "        CREATE KEYSPACE IF NOT EXISTS \n",
    "          sparkify \n",
    "        WITH REPLICATION = {\n",
    "            'class': 'SimpleStrategy', \n",
    "            'replication_factor': 1\n",
    "        }\n",
    "    \"\"\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    session.set_keyspace('sparkify')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create queries to ask the following three questions of the data\n",
    "\n",
    "1. Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4\n",
    "\n",
    "\n",
    "2. Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "    \n",
    "\n",
    "3. Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 1\n",
    "\n",
    "**Query:** Give the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4.\n",
    "\n",
    "The primary key is (`session_id`, `item_in_session`) because we put those would go in our `WHERE` clause. I have set the partition key to `session_id` because we would want to store all of the information for a single session on the same node, rather than to have it scattered across nodes. `item_in_session` is the clustering column because we might want to order by this column or filter by it.\n",
    "\n",
    "### CQL Queries and Table Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CQL Queries: Give me the artist, song title and song's length in the \n",
    "# music app history that was heard during  sessionId = 338, and itemInSession  = 4\n",
    "select_query_1 = \"\"\"\n",
    "    SELECT \n",
    "      artist, \n",
    "      song, \n",
    "      length \n",
    "    FROM \n",
    "      song_info \n",
    "    WHERE \n",
    "      session_id = 338 AND \n",
    "      item_in_session = 4\n",
    "\"\"\"\n",
    "\n",
    "create_query_1 = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS\n",
    "      song_info (\n",
    "        session_id int,\n",
    "        item_in_session int,\n",
    "        artist text,\n",
    "        length float,\n",
    "        song text,\n",
    "        PRIMARY KEY (session_id, item_in_session)\n",
    "      )\n",
    "\"\"\"\n",
    "\n",
    "insert_query_1 = \"\"\"\n",
    "    INSERT INTO \n",
    "      song_info (\n",
    "        session_id,\n",
    "        item_in_session,\n",
    "        artist,\n",
    "        length,\n",
    "        song\n",
    "      )\n",
    "    VALUES\n",
    "      (%s, %s, %s, %s, %s)\n",
    "\"\"\"\n",
    "        \n",
    "try:\n",
    "    session.execute(create_query_1)\n",
    "except Exception as e:\n",
    "    print(e)                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Read filtered CSV\n",
    "with open('event_datafile_new.csv', encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    \n",
    "    # Skip header row (column names)\n",
    "    next(csvreader)\n",
    "    \n",
    "    for line in csvreader:\n",
    "        \n",
    "        # Insert each row into table\n",
    "        session.execute(\n",
    "            insert_query_1, \n",
    "            (int(line[8]), int(line[3]), line[0], float(line[5]), line[9])\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify Data Insertion\n",
    "\n",
    "`pandas_factory()` and the two subsequent lines of code set up the infrastructure for all other queries to be displayed as DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Faithless</td>\n",
       "      <td>Music Matters (Mark Knight Dub)</td>\n",
       "      <td>495.307312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      artist                             song      length\n",
       "0  Faithless  Music Matters (Mark Knight Dub)  495.307312"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define function that will instantiate a dataframe row factory\n",
    "def pandas_factory(colnames, rows):\n",
    "    return pd.DataFrame(rows, columns=colnames)\n",
    "\n",
    "# Specify to use the pandas_factory\n",
    "session.row_factory = pandas_factory\n",
    "\n",
    "# Default is 50000, but our tables are pretty small so ignore\n",
    "session.default_fetch_size = None\n",
    "\n",
    "# Execute query \n",
    "rows = session.execute(select_query_1)\n",
    "df = rows._current_rows\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 2\n",
    "\n",
    "**Query:** Give only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182.\n",
    "\n",
    "The primary key is (`user_id`, `session_id`, `item_in_session`) because they will appear in our WHERE clause for a query like this. `user_id` is the partition key because we will want to store all information by the same user on a single node. Next, because we know we want to filter by `session_id` and return results sorted by `item_in_session`, then we must use those two columns as clustering columns in that order.\n",
    "\n",
    "### CQL Queries and Table Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRIMARY KEY (user_id, session_id, item_in_session)\n",
    "select_query_2 = \"\"\"\n",
    "    SELECT \n",
    "      artist, \n",
    "      song, \n",
    "      first_name, \n",
    "      last_name \n",
    "    FROM \n",
    "      users_songs \n",
    "    WHERE \n",
    "      user_id = 10 AND \n",
    "      session_id = 182\n",
    "\"\"\"\n",
    "\n",
    "create_query_2 = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS\n",
    "      users_songs (\n",
    "        user_id int,\n",
    "        session_id int,\n",
    "        item_in_session int,\n",
    "        artist text,\n",
    "        first_name text,\n",
    "        last_name text,\n",
    "        song text,\n",
    "        PRIMARY KEY (user_id, session_id, item_in_session)\n",
    "      )\n",
    "\"\"\"\n",
    "\n",
    "insert_query_2 = \"\"\"\n",
    "    INSERT INTO \n",
    "      users_songs (\n",
    "        user_id,\n",
    "        session_id,\n",
    "        item_in_session,\n",
    "        artist,\n",
    "        first_name,\n",
    "        last_name,\n",
    "        song\n",
    "      )\n",
    "    VALUES\n",
    "      (%s, %s, %s, %s, %s, %s, %s)\n",
    "\"\"\"\n",
    "        \n",
    "try:\n",
    "    session.execute(create_query_2)\n",
    "except Exception as e:\n",
    "    print(e)                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Read filtered CSV\n",
    "with open('event_datafile_new.csv', encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    \n",
    "    # Skip header row (column names)\n",
    "    next(csvreader)\n",
    "    \n",
    "    for line in csvreader:\n",
    "        \n",
    "        # Insert each row into table\n",
    "        session.execute(\n",
    "            insert_query_2, \n",
    "            (\n",
    "                int(line[10]),\n",
    "                int(line[8]),\n",
    "                int(line[3]), \n",
    "                line[0], \n",
    "                line[1], \n",
    "                line[4], \n",
    "                line[9]   \n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify Data Insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Down To The Bone</td>\n",
       "      <td>Keep On Keepin' On</td>\n",
       "      <td>Sylvie</td>\n",
       "      <td>Cruz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Three Drives</td>\n",
       "      <td>Greece 2000</td>\n",
       "      <td>Sylvie</td>\n",
       "      <td>Cruz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sebastien Tellier</td>\n",
       "      <td>Kilometer</td>\n",
       "      <td>Sylvie</td>\n",
       "      <td>Cruz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lonnie Gordon</td>\n",
       "      <td>Catch You Baby (Steve Pitron &amp; Max Sanna Radio...</td>\n",
       "      <td>Sylvie</td>\n",
       "      <td>Cruz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              artist                                               song  \\\n",
       "0   Down To The Bone                                 Keep On Keepin' On   \n",
       "1       Three Drives                                        Greece 2000   \n",
       "2  Sebastien Tellier                                          Kilometer   \n",
       "3      Lonnie Gordon  Catch You Baby (Steve Pitron & Max Sanna Radio...   \n",
       "\n",
       "  first_name last_name  \n",
       "0     Sylvie      Cruz  \n",
       "1     Sylvie      Cruz  \n",
       "2     Sylvie      Cruz  \n",
       "3     Sylvie      Cruz  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute query \n",
    "rows = session.execute(select_query_2)\n",
    "df = rows._current_rows\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 3\n",
    "\n",
    "**Query:** Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "The primary key is (`song`, `user_id`) with partition key `song` because we want to keep all users who listen to the same song on a single node and filter by song. We use `user_id` as a clustering column because we can optionally filter by that column.\n",
    "\n",
    "\n",
    "### CQL Queries and Table Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_query_3 = \"\"\"\n",
    "    SELECT \n",
    "      first_name, \n",
    "      last_name \n",
    "    FROM \n",
    "      user_name \n",
    "    WHERE \n",
    "      song = 'All Hands Against His Own'\n",
    "\"\"\"\n",
    "\n",
    "create_query_3 = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS\n",
    "      user_name (\n",
    "        song text,\n",
    "        user_id int,\n",
    "        last_name text,\n",
    "        first_name text,\n",
    "        PRIMARY KEY (song, user_id)\n",
    "      )\n",
    "\"\"\"\n",
    "\n",
    "insert_query_3 = \"\"\"\n",
    "    INSERT INTO \n",
    "      user_name (\n",
    "        song,\n",
    "        user_id,\n",
    "        first_name,\n",
    "        last_name\n",
    "      )\n",
    "    VALUES\n",
    "      (%s, %s, %s, %s)\n",
    "\"\"\"\n",
    "        \n",
    "try:\n",
    "    session.execute(create_query_3)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read filtered CSV\n",
    "with open('event_datafile_new.csv', encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    \n",
    "    # Skip header row (column names)\n",
    "    next(csvreader)\n",
    "    \n",
    "    for line in csvreader:\n",
    "        \n",
    "        # Insert each row into table\n",
    "        session.execute(\n",
    "            insert_query_3, (line[9], int(line[10]), line[1], line[4])\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify Data Insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jacqueline</td>\n",
       "      <td>Lynch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tegan</td>\n",
       "      <td>Levine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sara</td>\n",
       "      <td>Johnson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   first_name last_name\n",
       "0  Jacqueline     Lynch\n",
       "1       Tegan    Levine\n",
       "2        Sara   Johnson"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute query \n",
    "rows = session.execute(select_query_3)\n",
    "df = rows._current_rows\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the tables before closing out the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_query_1 = \"DROP TABLE song_info\"\n",
    "drop_query_2 = \"DROP TABLE users_songs\"\n",
    "drop_query_3 = \"DROP TABLE user_name\"\n",
    "\n",
    "drop_queries = [drop_query_1, drop_query_2, drop_query_3]\n",
    "\n",
    "for query in drop_queries:\n",
    "    session.execute(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close the session and cluster connectionÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
